{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d04605f8-ba9f-49aa-883a-f29dfca3fafa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.streaming import StreamingContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dfe018cc-c63e-4454-95a7-70ec73a2a2b8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def initialize_spark():\n",
    "    \"\"\"Initialize SparkSession and StreamingContext.\"\"\"\n",
    "    # Create a SparkSession specifying master and app name\n",
    "    spark = SparkSession.builder \\\n",
    "        .master(\"local[2]\") \\\n",
    "        .appName(\"NYSEStockStreamingApp\") \\\n",
    "        .getOrCreate()\n",
    "    \n",
    "    # Create a Streaming Context with a batch interval of 1 second\n",
    "    ssc = StreamingContext(spark.sparkContext, 1)\n",
    "    \n",
    "    return spark, ssc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "36b574e2-74bf-40a8-a4f6-b8687665a334",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_previous_max_prices(spark):\n",
    "    \"\"\"Load previous max prices from a CSV file into an RDD and cache it for later use.\"\"\"\n",
    "    previous_max_prices_df = spark.read.csv(\"previous_max_price.csv\", header=False, inferSchema=True)\n",
    "    previous_max_prices = previous_max_prices_df.rdd.map(lambda row: (row[0], float(row[1]))).cache()\n",
    "    \n",
    "    return previous_max_prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ff63b106-bcfb-4e4d-8443-0fab71273fc2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def process_stock_data(lines, previous_max_prices):\n",
    "    \"\"\"Process streaming stock data.\"\"\"\n",
    "    # Map each line to a tuple of (stock symbol, (timestamp, price)) and convert price to float\n",
    "    stock_data = lines.map(lambda line: line.split(\",\")).map(lambda x: (x[0], (x[1], float(x[2]))))\n",
    "    \n",
    "    # Join the stream data with previous max prices data\n",
    "    joined_data = stock_data.transform(lambda rdd: rdd.join(previous_max_prices))\n",
    "    \n",
    "    # Filter the joined data to keep only the records where the current price is greater than or equal to the previous max price\n",
    "    filtered_data = joined_data.filter(lambda x: x[1][0][1] >= x[1][1])\n",
    "    \n",
    "    return filtered_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "750df42d-7872-40ff-bff1-67c9b355a304",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calculate_percentage_change(data):\n",
    "    \"\"\"Calculate the percentage increase or decrease and format the output.\"\"\"\n",
    "    stock_symbol, ((timestamp, current_price), previous_max_price) = data\n",
    "    percentage_change = ((current_price - previous_max_price) / previous_max_price) * 100\n",
    "    return f\"{stock_symbol}: Current Price: {current_price}, Previous Max Price: {previous_max_price}, Percentage Change: {percentage_change:.2f}%\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c0e836-5e13-4f07-ad35-cc56964e151f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\pyspark\\streaming\\context.py:72: FutureWarning: DStream is deprecated as of Spark 3.4.0. Migrate to Structured Streaming.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "Time: 2024-03-04 20:57:34\n",
      "-------------------------------------------\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2024-03-04 20:57:35\n",
      "-------------------------------------------\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2024-03-04 20:57:36\n",
      "-------------------------------------------\n",
      "JAS: Current Price: 50.43, Previous Max Price: 38.06, Percentage Change: 32.50%\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2024-03-04 20:57:37\n",
      "-------------------------------------------\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2024-03-04 20:57:38\n",
      "-------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    # Initialize SparkSession and StreamingContext\n",
    "    spark, ssc = initialize_spark()\n",
    "    \n",
    "    # Load previous max prices\n",
    "    previous_max_prices = load_previous_max_prices(spark)\n",
    "    \n",
    "    # Create a DStream by connecting to a socket on localhost and port 9999\n",
    "    lines = ssc.socketTextStream(\"localhost\", 9999)\n",
    "    \n",
    "    # Process streaming stock data\n",
    "    filtered_data = process_stock_data(lines, previous_max_prices)\n",
    "    \n",
    "    # Apply the percentage change calculation and format the output\n",
    "    formatted_data = filtered_data.map(calculate_percentage_change)\n",
    "    \n",
    "    # Print the formatted data\n",
    "    formatted_data.pprint()\n",
    "    \n",
    "    # Start the streaming context\n",
    "    ssc.start()\n",
    "    \n",
    "    # Wait for the termination of the streaming context\n",
    "    ssc.awaitTermination()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c97744a1-ea34-436b-91db-9a743d79b10d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
